{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a517ebe",
   "metadata": {},
   "source": [
    "PLEASE NOTE:\n",
    "\n",
    "This file is only checkng how the created LimeExplainer and SHAPExplainer will look in the notebook for all the 2 models ie logistic and xgboost. \n",
    "\n",
    "This should only be run after creating .pkl from the models using src/models/logistic_baseline.py and src/models/xgboost_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e79681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "import shap\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08d97fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIME Explanation:\n",
      "\n",
      "Credit Risk:\n",
      "  economic: 0.040\n",
      "  volatility: -0.033\n",
      "  affect: 0.032\n",
      "  adversely: 0.031\n",
      "  Market: 0.023\n",
      "  and: -0.019\n",
      "\n",
      "Legal/Regulatory Risk:\n",
      "  business: -0.023\n",
      "  economic: 0.023\n",
      "  and: 0.017\n",
      "  volatility: -0.010\n",
      "  our: 0.009\n",
      "  Market: -0.002\n",
      "\n",
      "Liquidity Risk:\n",
      "  affect: 0.031\n",
      "  adversely: 0.030\n",
      "  economic: 0.025\n",
      "  volatility: -0.020\n",
      "  our: 0.008\n",
      "  uncertainty: 0.007\n",
      "\n",
      "Market Risk:\n",
      "  Market: 0.060\n",
      "  economic: 0.043\n",
      "  and: -0.035\n",
      "  volatility: -0.025\n",
      "  adversely: 0.022\n",
      "  affect: 0.017\n",
      "\n",
      "Operational Risk:\n",
      "  affect: 0.046\n",
      "  business: 0.041\n",
      "  volatility: -0.035\n",
      "  adversely: 0.031\n",
      "  economic: 0.013\n",
      "  Market: -0.005\n",
      "\n",
      "Reputational Risk:\n",
      "  business: 0.039\n",
      "  volatility: -0.032\n",
      "  affect: 0.027\n",
      "  adversely: 0.026\n",
      "  economic: -0.025\n",
      "  Market: -0.022\n",
      "\n",
      "Strategic Risk:\n",
      "  adversely: 0.022\n",
      "  business: 0.021\n",
      "  uncertainty: 0.018\n",
      "  volatility: -0.018\n",
      "  affect: 0.016\n",
      "  Market: 0.014\n"
     ]
    }
   ],
   "source": [
    "class LIMEExplainer:\n",
    "    def __init__(self, model, class_names):\n",
    "        self.model = model\n",
    "        self.class_names = class_names\n",
    "        self.explainer = LimeTextExplainer(class_names=class_names)\n",
    "    \n",
    "    def explain(self, text, num_features=10):\n",
    "        def predict_proba_fn(texts):\n",
    "            return self.model.predict_proba(texts)\n",
    "\n",
    "        probs = self.model.predict_proba([text])[0]\n",
    "\n",
    "        exp = self.explainer.explain_instance(\n",
    "            text,\n",
    "            predict_proba_fn,\n",
    "            labels=list(np.where(probs > 0.0)[0]),\n",
    "            num_features=num_features,\n",
    "            num_samples=500\n",
    "        )\n",
    "\n",
    "        explanations = {}\n",
    "\n",
    "        for class_idx in exp.local_exp:\n",
    "            class_name = self.class_names[class_idx]\n",
    "            explanations[class_name] = {\n",
    "                \"word_weights\": exp.as_list(label=class_idx),\n",
    "                \"score\": probs[class_idx]\n",
    "            }\n",
    "\n",
    "        return explanations\n",
    "\n",
    "    \n",
    "    def get_top_words(self, explanation, class_name, k=10):\n",
    "        \"\"\"Get top-k words for a class\"\"\"\n",
    "        word_weights = explanation[class_name]['word_weights']\n",
    "        sorted_weights = sorted(word_weights, key=lambda x: abs(x[1]), reverse=True)\n",
    "        return sorted_weights[:k]\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    import pickle\n",
    "    \n",
    "    # Load model\n",
    "    artifact_folder = Path(__name__).resolve().parent.parent / \"results/model_artifacts\"\n",
    "    with open(artifact_folder / \"logistic_baseline.pkl\", 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "    \n",
    "    # Mock model wrapper\n",
    "    class ModelWrapper:\n",
    "        def __init__(self, model_data):\n",
    "            self.vectorizer = model_data['vectorizer']\n",
    "            self.models = model_data['models']\n",
    "            self.mlb = model_data['mlb']\n",
    "        \n",
    "        def predict_proba(self, texts):\n",
    "            X_vec = self.vectorizer.transform(texts)\n",
    "            probas = np.zeros((len(texts), len(self.mlb.classes_)))\n",
    "            for i, class_name in enumerate(self.mlb.classes_):\n",
    "                probas[:, i] = self.models[class_name].predict_proba(X_vec)[:, 1]\n",
    "            return probas\n",
    "    \n",
    "    model = ModelWrapper(model_data)\n",
    "    explainer = LIMEExplainer(model, model_data['mlb'].classes_)\n",
    "    \n",
    "    # Test\n",
    "    test_text = \"Market volatility and economic uncertainty may adversely affect our business.\"\n",
    "    explanation = explainer.explain(test_text)\n",
    "    \n",
    "    print(\"LIME Explanation:\")\n",
    "    for class_name in explanation:\n",
    "        print(f\"\\n{class_name}:\")\n",
    "        top_words = explainer.get_top_words(explanation, class_name, k=6)\n",
    "        for word, weight in top_words:\n",
    "            print(f\"  {word}: {weight:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cdbc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIME Explanation:\n",
      "\n",
      "Credit Risk:\n",
      "  This: 0.000\n",
      "  will: 0.000\n",
      "  tarnish: 0.000\n",
      "  our: 0.000\n",
      "  image: 0.000\n",
      "\n",
      "Legal/Regulatory Risk:\n",
      "  This: 0.000\n",
      "  will: 0.000\n",
      "  tarnish: 0.000\n",
      "  our: 0.000\n",
      "  image: 0.000\n",
      "\n",
      "Liquidity Risk:\n",
      "  This: -0.000\n",
      "  tarnish: -0.000\n",
      "  image: -0.000\n",
      "  will: -0.000\n",
      "  our: 0.000\n",
      "\n",
      "Market Risk:\n",
      "  This: 0.000\n",
      "  will: 0.000\n",
      "  tarnish: 0.000\n",
      "  our: 0.000\n",
      "  image: 0.000\n",
      "\n",
      "Operational Risk:\n",
      "  This: 0.000\n",
      "  tarnish: 0.000\n",
      "  image: 0.000\n",
      "  will: 0.000\n",
      "  our: -0.000\n",
      "\n",
      "Reputational Risk:\n",
      "  This: 0.000\n",
      "  tarnish: 0.000\n",
      "  image: 0.000\n",
      "  will: 0.000\n",
      "  our: -0.000\n",
      "\n",
      "Strategic Risk:\n",
      "  This: 0.000\n",
      "  will: 0.000\n",
      "  tarnish: 0.000\n",
      "  our: 0.000\n",
      "  image: 0.000\n"
     ]
    }
   ],
   "source": [
    "class LIMEExplainerXGBoost:\n",
    "    def __init__(self, model, class_names):\n",
    "        self.model = model\n",
    "        self.class_names = class_names\n",
    "        self.explainer = LimeTextExplainer(class_names=class_names)\n",
    "    \n",
    "    def explain(self, text, num_features=10):\n",
    "        def predict_proba_fn(texts):\n",
    "            return self.model.predict_proba(texts)\n",
    "\n",
    "        probs = self.model.predict_proba([text])[0]\n",
    "\n",
    "        exp = self.explainer.explain_instance(\n",
    "            text,\n",
    "            predict_proba_fn,\n",
    "            labels=list(np.where(probs > 0.0)[0]),\n",
    "            num_features=num_features,\n",
    "            num_samples=500\n",
    "        )\n",
    "\n",
    "        explanations = {}\n",
    "\n",
    "        for class_idx in exp.local_exp:\n",
    "            class_name = self.class_names[class_idx]\n",
    "            explanations[class_name] = {\n",
    "                \"word_weights\": exp.as_list(label=class_idx),\n",
    "                \"score\": probs[class_idx]\n",
    "            }\n",
    "\n",
    "        return explanations\n",
    "\n",
    "    \n",
    "    def get_top_words(self, explanation, class_name, k=10):\n",
    "        \"\"\"Get top-k words for a class\"\"\"\n",
    "        word_weights = explanation[class_name]['word_weights']\n",
    "        sorted_weights = sorted(word_weights, key=lambda x: abs(x[1]), reverse=True)\n",
    "        return sorted_weights[:k]\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    import pickle\n",
    "    \n",
    "    # Load model\n",
    "    artifact_folder = Path(__name__).resolve().parent.parent / \"results/model_artifacts\"\n",
    "    with open(artifact_folder / \"xgboost.pkl\", 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "    \n",
    "    # Mock model wrapper\n",
    "    class ModelWrapper:\n",
    "        def __init__(self, model_data):\n",
    "            self.vectorizer = model_data['vectorizer']\n",
    "            self.models = model_data['models']\n",
    "            self.mlb = model_data['mlb']\n",
    "        \n",
    "        def predict_proba(self, texts):\n",
    "            X_vec = self.vectorizer.transform(texts)\n",
    "            probas = np.zeros((len(texts), len(self.mlb.classes_)))\n",
    "            for i, class_name in enumerate(self.mlb.classes_):\n",
    "                probas[:, i] = self.models[class_name].predict_proba(X_vec)[:, 1]\n",
    "            return probas\n",
    "    \n",
    "    model = ModelWrapper(model_data)\n",
    "    explainer = LIMEExplainerXGBoost(model, model_data['mlb'].classes_)\n",
    "    \n",
    "    # Test\n",
    "    test_text = \"Market volatility and economic uncertainty may adversely affect our business.\"\n",
    "    explanation = explainer.explain(test_text)\n",
    "    \n",
    "    print(\"LIME Explanation:\")\n",
    "    for class_name in explanation:\n",
    "        print(f\"\\n{class_name}:\")\n",
    "        top_words = explainer.get_top_words(explanation, class_name, k=6)\n",
    "        for word, weight in top_words:\n",
    "            print(f\"  {word}: {weight:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a5467ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP Explanation:\n",
      "  credit: 0.3339\n",
      "  credit risk: 0.0846\n",
      "  risk: 0.0655\n",
      "  loan: 0.0642\n",
      "  facilities: 0.0589\n",
      "  come: -0.0257\n",
      "  debt: -0.0219\n",
      "  financial: -0.0215\n",
      "  nrg: -0.0194\n",
      "  product: 0.0133\n"
     ]
    }
   ],
   "source": [
    "# src/explainers/shap_explainer.py\n",
    "\n",
    "class SHAPExplainer:\n",
    "    def __init__(self, model, model_type='logistic'):\n",
    "        \"\"\"\n",
    "        model_type: 'logistic', 'xgboost', or 'neural'\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.model_type = model_type\n",
    "        self.explainer = None\n",
    "        \n",
    "    def fit(self, X_train, max_samples=100):\n",
    "        \"\"\"Initialize explainer with background data\"\"\"\n",
    "        if self.model_type == 'logistic':\n",
    "            # For sklearn models - use one class as example\n",
    "            X_train_vec = self.model.vectorizer.transform(X_train[:max_samples])\n",
    "            # Create explainer for first class\n",
    "            first_class = list(self.model.models.keys())[0]\n",
    "            self.explainer = shap.LinearExplainer(\n",
    "                self.model.models[first_class],\n",
    "                X_train_vec\n",
    "            )\n",
    "            self.explainer_type = 'single'\n",
    "            \n",
    "        elif self.model_type == 'xgboost':\n",
    "            # Use TreeExplainer for each class\n",
    "            self.explainer = {}\n",
    "            for class_name in self.model.models:\n",
    "                self.explainer[class_name] = shap.TreeExplainer(self.model.models[class_name])\n",
    "            self.explainer_type = 'multi'\n",
    "            \n",
    "        else:  # neural\n",
    "            # Use KernelExplainer (slower but model-agnostic)\n",
    "            def predict_fn(texts):\n",
    "                return self.model.predict_proba(texts)\n",
    "            \n",
    "            self.explainer = shap.KernelExplainer(predict_fn, X_train[:max_samples])\n",
    "            self.explainer_type = 'single'\n",
    "    \n",
    "    def explain(self, text, class_name=None):\n",
    "        \"\"\"Generate SHAP explanation\"\"\"\n",
    "        X_vec = self.model.vectorizer.transform([text])\n",
    "        \n",
    "        if self.model_type == 'xgboost' and class_name:\n",
    "            shap_values = self.explainer[class_name].shap_values(X_vec)\n",
    "        else:\n",
    "            shap_values = self.explainer.shap_values(X_vec)\n",
    "        \n",
    "        # Get feature names\n",
    "        feature_names = self.model.vectorizer.get_feature_names_out()\n",
    "        \n",
    "        # Extract non-zero features\n",
    "        if hasattr(shap_values, 'values'):\n",
    "            values = shap_values.values[0]\n",
    "        elif isinstance(shap_values, list):\n",
    "            values = shap_values[0]\n",
    "        else:\n",
    "            values = shap_values[0]\n",
    "        \n",
    "        # Map to words in original text\n",
    "        word_weights = []\n",
    "        for idx, val in enumerate(values):\n",
    "            if abs(val) > 0.001:  # Threshold\n",
    "                word_weights.append((feature_names[idx], float(val)))\n",
    "        \n",
    "        # Sort by absolute value\n",
    "        word_weights.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        \n",
    "        return word_weights\n",
    "    \n",
    "    def get_top_words(self, explanation, k=10):\n",
    "        \"\"\"Get top-k words\"\"\"\n",
    "        return explanation[:k]\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    import pickle\n",
    "    \n",
    "    # Load model\n",
    "    artifact_folder = Path(__name__).resolve().parent.parent / \"results/model_artifacts\"\n",
    "    with open(artifact_folder / 'logistic_baseline.pkl', 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "    \n",
    "    class ModelWrapper:\n",
    "        def __init__(self, model_data):\n",
    "            self.vectorizer = model_data['vectorizer']\n",
    "            self.models = model_data['models']\n",
    "            self.mlb = model_data['mlb']\n",
    "        \n",
    "        def predict_proba(self, texts):\n",
    "            X_vec = self.vectorizer.transform(texts)\n",
    "            probas = np.zeros((len(texts), len(self.mlb.classes_)))\n",
    "            for i, class_name in enumerate(self.mlb.classes_):\n",
    "                probas[:, i] = self.models[class_name].predict_proba(X_vec)[:, 1]\n",
    "            return probas\n",
    "    \n",
    "    model = ModelWrapper(model_data)\n",
    "    \n",
    "    # Need some training data for background\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('../data/risk_data.csv')\n",
    "    X_train = df['paragraph_cleaned'].values[:100]\n",
    "    \n",
    "    explainer = SHAPExplainer(model, model_type='logistic')\n",
    "    explainer.fit(X_train, max_samples=50)\n",
    "    \n",
    "    # Test\n",
    "    test_text = \"Loan facilities are hard to come by therefore we may have credit risk.\"\n",
    "    explanation = explainer.explain(test_text)\n",
    "    \n",
    "    print(\"SHAP Explanation:\")\n",
    "    for word, weight in explanation[:10]:\n",
    "        print(f\"  {word}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471f9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP Explanation:\n",
      "  law: 3.4330\n",
      "  regulation: -0.5073\n",
      "  business: 0.4261\n",
      "  regulatory: -0.3301\n",
      "  operation: 0.3134\n",
      "  cost: -0.2651\n",
      "  include: -0.2512\n",
      "  adversely affect: -0.1193\n",
      "  operating: 0.1049\n",
      "  meet: 0.0993\n"
     ]
    }
   ],
   "source": [
    "class SHAPExplainer:\n",
    "    def __init__(self, model, model_type='logistic'):\n",
    "        \"\"\"\n",
    "        model_type: 'logistic', 'xgboost', or 'neural'\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.model_type = model_type\n",
    "        self.explainer = None\n",
    "        \n",
    "    def fit(self, X_train, max_samples=100):\n",
    "        \"\"\"Initialize explainer with background data\"\"\"\n",
    "        if self.model_type == 'logistic':\n",
    "            # For sklearn models - use one class as example\n",
    "            X_train_vec = self.model.vectorizer.transform(X_train[:max_samples])\n",
    "            # Create explainer for first class\n",
    "            first_class = list(self.model.models.keys())[0]\n",
    "            self.explainer = shap.LinearExplainer(\n",
    "                self.model.models[first_class],\n",
    "                X_train_vec\n",
    "            )\n",
    "            self.explainer_type = 'single'\n",
    "            \n",
    "        elif self.model_type == 'xgboost':\n",
    "            # Use TreeExplainer for each class\n",
    "            self.explainer = {}\n",
    "            for class_name in self.model.models:\n",
    "                self.explainer[class_name] = shap.TreeExplainer(self.model.models[class_name])\n",
    "            self.explainer_type = 'multi'\n",
    "            \n",
    "        else:  # neural\n",
    "            # Use KernelExplainer (slower but model-agnostic)\n",
    "            def predict_fn(texts):\n",
    "                return self.model.predict_proba(texts)\n",
    "            \n",
    "            self.explainer = shap.KernelExplainer(predict_fn, X_train[:max_samples])\n",
    "            self.explainer_type = 'single'\n",
    "    \n",
    "    def explain(self, text, class_name):\n",
    "        X_vec = self.model.vectorizer.transform([text])\n",
    "        feature_names = self.model.vectorizer.get_feature_names_out()\n",
    "\n",
    "        if self.model_type == 'xgboost':\n",
    "            explainer = self.explainer[class_name]\n",
    "            shap_values = explainer.shap_values(X_vec)\n",
    "\n",
    "            # XGBoost binary classifier â†’ shape (1, n_features)\n",
    "            values = shap_values[0]\n",
    "\n",
    "        else:\n",
    "            shap_values = self.explainer.shap_values(X_vec)\n",
    "            values = shap_values[0]\n",
    "\n",
    "        word_weights = [\n",
    "            (feature_names[i], float(values[i]))\n",
    "            for i in range(len(values))\n",
    "            if abs(values[i]) > 0.001\n",
    "        ]\n",
    "\n",
    "        word_weights.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        return word_weights\n",
    "    \n",
    "    def get_top_words(self, explanation, k=10):\n",
    "        \"\"\"Get top-k words\"\"\"\n",
    "        return explanation[:k]\n",
    "\n",
    "# Usage\n",
    "if __name__ == \"__main__\":\n",
    "    import pickle\n",
    "    \n",
    "    # Load model\n",
    "    artifact_folder = Path(__name__).resolve().parent.parent / \"results/model_artifacts\"\n",
    "    with open(artifact_folder / 'xgboost.pkl', 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "    \n",
    "    class ModelWrapper:\n",
    "        def __init__(self, model_data):\n",
    "            self.vectorizer = model_data['vectorizer']\n",
    "            self.models = model_data['models']\n",
    "            self.mlb = model_data['mlb']\n",
    "        \n",
    "        def predict_proba(self, texts):\n",
    "            X_vec = self.vectorizer.transform(texts)\n",
    "            probas = np.zeros((len(texts), len(self.mlb.classes_)))\n",
    "            for i, class_name in enumerate(self.mlb.classes_):\n",
    "                probas[:, i] = self.models[class_name].predict_proba(X_vec)[:, 1]\n",
    "            return probas\n",
    "    \n",
    "    model = ModelWrapper(model_data)\n",
    "    \n",
    "    # Need some training data for background\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('../data/risk_data.csv')\n",
    "    X_train = df['paragraph_cleaned'].values[:100]\n",
    "    \n",
    "    explainer = SHAPExplainer(model, model_type='xgboost')\n",
    "    explainer.fit(X_train, max_samples=50)\n",
    "    \n",
    "    # Test\n",
    "    test_text = df['paragraph'].iloc[-1]\n",
    "    explanation = explainer.explain(test_text, class_name=\"Legal/Regulatory Risk\")\n",
    "    \n",
    "    print(\"SHAP Explanation:\")\n",
    "    for word, weight in explanation[:10]:\n",
    "        print(f\"  {word}: {weight:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
